{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://openenergy-platform.org/static/OEP_logo_2_no_text.svg\" alt=\"OpenEnergy Platform\" height=\"100\" width=\"100\"  align=\"left\"/>\n",
    "\n",
    "# OpenEnergyPlatform\n",
    "<br><br>\n",
    "\n",
    "## Usage of OpenEnergyPlatform API-Dialect (oedialect)\n",
    "Repository: https://github.com/openego/oedialect <br>\n",
    "Documentation: http://oep-data-interface.readthedocs.io/en/latest/api/how_to.html\n",
    "\n",
    "Please report bugs and improvements here: https://github.com/OpenEnergyPlatform/oedialect/issues <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__copyright__ = \"Reiner Lemoine Institut\"\n",
    "__license__   = \"GNU Affero General Public License Version 3 (AGPL-3.0)\"\n",
    "__url__       = \"https://github.com/openego/data_processing/blob/master/LICENSE\"\n",
    "__author__    = \"christian-rli, oakca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import getpass\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import oedialect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from a csv file and uploading it to the oedb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a read_csv function which makes importing a csv-file rather comfortable. It reads csv into a DataFrame. By default, it assumes that the fields are comma-separated. Our example file has columns with semicolons as separators, so we have to specify this when reading the file. \n",
    "\n",
    "The example file for this tutorial ('DataTemplate.csv') is in a 'data' directory, one level above the file for this tutorial. Make sure to adapt the path to the file you're using if your file is located elsewhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.read_csv('../data/TemplateData.csv', encoding='utf8', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first three lines of our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to OEP\n",
    "\n",
    "If we want to upload data to the OEP we first need to connect to it, using our OEP user name and token. \n",
    "Note: You ca view your token on your OEP profile page after logging in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White spaces in the username are fine!\n",
    "user = input('Enter OEP-username:')\n",
    "token = getpass.getpass('Token:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create an sql-alchemy-engine. The engine is what 'speaks' oedialect to the data base api. We need to tell it where the data base is and pass our credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Engine:\n",
    "OEP_URL = 'openenergy-platform.org' #'193.175.187.164' #'oep.iks.cs.ovgu.de'\n",
    "OED_STRING = f'postgresql+oedialect://{user}:{token}@{OEP_URL}'\n",
    "\n",
    "engine = sa.create_engine(OED_STRING)\n",
    "metadata = sa.MetaData(bind=engine)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a Table\n",
    "\n",
    "We need to tell the data base what columns and datatypes we are about to upload. In our case we have four columns, two of which are text, one is integer and the last is float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'example_dialect_table'\n",
    "schema_name = 'sandbox'\n",
    "\n",
    "ExampleTable = sa.Table(\n",
    "    table_name,\n",
    "    metadata,\n",
    "    sa.Column('variable', sa.VARCHAR(50)),\n",
    "    sa.Column('unit', sa.VARCHAR(50)),\n",
    "    sa.Column('year', sa.INTEGER),\n",
    "    sa.Column('value', sa.FLOAT(50)),\n",
    "    schema=schema_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the new Table\n",
    "\n",
    "Now we tell our engine to connect to the data base and create the defined table within the chosen schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine.connect()\n",
    "print('Connection established')\n",
    "if not engine.dialect.has_table(conn, table_name, schema_name):\n",
    "    ExampleTable.create()\n",
    "    print('Created table')\n",
    "else:\n",
    "    print('Table already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data into Table\n",
    " \n",
    "Uploading the information from our DataFrame is now done with a single command. Uploading data in this way will always delete the content of the table and refill it with new values every time. If you change 'replace' to 'append', the data entries will be added to the preexisting ones. (Connecting and uploading may take a minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try: \n",
    "    example_df.to_sql(table_name, conn, schema_name, if_exists='replace')\n",
    "    print('Inserted to ' + table_name)\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also insert data manually into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "try:\n",
    "    insert_statement = ExampleTable.insert().values(\n",
    "        [\n",
    "            dict(variable='fairy dust', unit='t', year=2020, value=200),\n",
    "            dict(variable='mana', unit='kg', year=1999, value=120),\n",
    "            dict(variable='the force', unit='l', year=1998, value=1100)\n",
    "        ]\n",
    "    )\n",
    "    session.execute(insert_statement)\n",
    "    session.commit()\n",
    "    print('Insert successful!')\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    raise\n",
    "    print('Insert incomplete!')\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select from Table\n",
    "\n",
    "Now  we can query our table to see if the data arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "print(session.query(ExampleTable).all())\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Query Result in DataFrame\n",
    "We can write the results of the query back into a DataFrame, where it's easier to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "df = pd.DataFrame(session.query(ExampleTable).all())\n",
    "session.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
