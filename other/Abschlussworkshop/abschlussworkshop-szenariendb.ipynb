{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://raw.githubusercontent.com/OpenEnergyPlatform/academy/develop/docs/data/img/OEP_logo_2_no_text.svg\" alt=\"OpenEnergy Platform\" height=\"75\" width=\"75\" align=\"left\"/>\n",
        "<img src=\"https://raw.githubusercontent.com/OpenEnergyPlatform/academy/develop/docs/data/img/rlilogo.png\" alt=\"RLI\" height=\"75\" width=\"75\" align=\"right\"/>\n",
        "\n",
        "# Uploading data to the OEP via script\n",
        "<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running this tutorial locally then use the requirements.txt to setup your environment. Otherwise make sure to install sqlalchemy>=1.3.0,<1.4 as version later then v1.4 do not support the oedialect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install oedialect pandas \"sqlalchemy~=1.3,<1.4\" requests oep-client\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import sqlalchemy as sa\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import oedialect\n",
        "import requests\n",
        "from oep_client import OepClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading data from a csv file into a dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pandas has a read_csv function which makes importing a csv-file rather comfortable. It reads csv into a DataFrame. By default, it assumes that the fields are comma-separated. Our example file has columns with semicolons as separators, so we have to specify this when reading the file. \n",
        "\n",
        "The example file for this tutorial ('DataTemplate.csv') is in a 'data' directory, one level above the file for this tutorial. Make sure to adapt the path to the file you're using if your file is located elsewhere.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_df = pd.read_csv('vg250-ew_2018-12-31.csv', encoding='utf8', sep=';', dtype={'RS': 'str'})\n",
        "example_df.columns = map(str.lower, example_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(example_df[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using the API\n",
        "\n",
        "If we want to upload data to the OEP we first need to connect to it, using our OEP user name and token. \n",
        "Note: You ca view your token on your OEP profile page after logging in.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEVER commit your token to a repository\n",
        "# get your token from an environment variable\n",
        "# or ask user\n",
        "token = os.environ.get(\"OEP_API_TOKEN\") or getpass.getpass('Token:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "oep_url = 'https://openenergyplatform.org'\n",
        "table = 'test_table_abschlussworkshop3'\n",
        "schema = 'model_draft'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define table\n",
        "# https://oep-data-interface.readthedocs.io/en/latest/api/how_to.html\n",
        "\n",
        "data = { \n",
        "    \"query\": { \n",
        "        \"columns\": [\n",
        "            { \"name\":\"id\", \"data_type\": \"bigserial\", \"is_nullable\": \"NO\" },\n",
        "            { \"name\":\"center_lon\", \"data_type\": \"numeric\" },\n",
        "            { \"name\":\"center_lat\", \"data_type\": \"numeric\" },\n",
        "            { \"name\":\"rs\", \"data_type\": \"varchar\", \"character_maximum_length\": \"50\"},\n",
        "            { \"name\":\"gen\", \"data_type\": \"varchar\", \"character_maximum_length\": \"50\" },\n",
        "            { \"name\":\"wsk\", \"data_type\": \"varchar\", \"character_maximum_length\": \"50\" },\n",
        "            { \"name\":\"ewz\", \"data_type\": \"numeric\" },\n",
        "            { \"name\":\"kfl\", \"data_type\": \"numeric\" },\n",
        "            { \"name\":\"hat_bez\", \"data_type\": \"boolean\" },\n",
        "            { \"name\":\"geometry_wkt\", \"data_type\": \"geometry\" },\n",
        "        ],\n",
        "        \"constraints\": [ { \"constraint_type\": \"PRIMARY KEY\", \"constraint_parameter\": \"id\" } ] \n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "requests.put(\n",
        "    oep_url + '/api/v0/schema/' + schema + '/tables/' + table + '/',\n",
        "    json=data, verify=True,\n",
        "    headers={'Authorization': 'Token {0}'.format(token)}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Delete table (do not delete if you want to proceed with next steps). PLese delte table after you finished with this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "requests.delete(\n",
        "    oep_url + '/api/v0/schema/' + schema + '/tables/' + table, verify=True,\n",
        "    headers={'Authorization': f'Token {token}'}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Uploading data to the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"query\": example_df.to_dict(orient='records')\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "requests.post(\n",
        "    oep_url + '/api/v0/schema/' + schema + '/tables/' + table + '/rows/new',\n",
        "    json=data, verify=True,\n",
        "    headers={'Authorization': 'Token {0}'.format(token)}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add Metadata to table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('metadata_testtable.json') as json_file:\n",
        "    data = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "requests.post(\n",
        "    oep_url + '/api/v0/schema/' + schema + '/tables/' + table + '/meta/',\n",
        "    json=data, verify=True,\n",
        "    headers={'Authorization': 'Token {0}'.format(token)}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload via sql-alchemy and oedialect\n",
        "\n",
        "Now we'll create an sql-alchemy-engine. The engine is what 'speaks' oedialect to the data base api. We need to tell it where the data base is and pass our credentials.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Engine:\n",
        "oed_string = f'postgresql+oedialect://:{token}@openenergyplatform.org'\n",
        "table_name = 'test_table_abschlussworkshop3'\n",
        "    \n",
        "engine = sa.create_engine(oed_string)\n",
        "metadata = sa.MetaData(bind=engine)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup a Table\n",
        "\n",
        "Define sqlalchemy columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ExampleTable = sa.Table(\n",
        "    table_name,\n",
        "    metadata,\n",
        "    sa.Column('id', sa.INTEGER),\n",
        "    sa.Column('center_lon', sa.FLOAT),\n",
        "    sa.Column('center_lat', sa.FLOAT),\n",
        "    sa.Column('rs', sa.CHAR(5)),\n",
        "    sa.Column('gen', sa.VARCHAR(50)),\n",
        "    sa.Column('wsk', sa.DATE),\n",
        "    sa.Column('ewz', sa.INTEGER),\n",
        "    sa.Column('kfl', sa.FLOAT),\n",
        "    sa.Column('hat_bez', sa.BOOLEAN),\n",
        "    sa.Column('geometry_wkt', sa.VARCHAR(50)),\n",
        "    schema=schema\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the new Table\n",
        "\n",
        "Now we tell our engine to connect to the data base and create the defined table within the chosen schema. \n",
        "\n",
        "https://openenergyplatform.org/dataedit/view/model_draft/test_table_abschlussworkshop2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = engine.connect()\n",
        "print('Connection established')\n",
        "if not engine.dialect.has_table(conn, table_name, schema):\n",
        "    ExampleTable.create()\n",
        "    print('Created table')\n",
        "else:\n",
        "    print('Table already exists')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete the Table\n",
        "Delete table (do not delete if you want to proceed with next steps). PLese delte table after you finished with this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# delete table\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "conn = engine.connect()\n",
        "print('Connection established')\n",
        "if engine.dialect.has_table(conn, table_name, schema):\n",
        "    ExampleTable.drop()\n",
        "    print('Deleted table')\n",
        "else:\n",
        "    print('Something went wrong')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Insert data into Table\n",
        " \n",
        "Uploading the information from our DataFrame is now done with a single command. Uploading data in this way will always delete the content of the table and refill it with new values every time. If you change 'replace' to 'append', the data entries will be added to the preexisting ones. (Connecting and uploading may take a minute.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "try:\n",
        "    insert_statement = ExampleTable.insert().values(example_df.to_dict(orient='records'))\n",
        "    session.execute(insert_statement)\n",
        "    session.commit()\n",
        "    print('Insert successful!')\n",
        "except Exception as e:\n",
        "    session.rollback()\n",
        "    print('Insert incomplete!')\n",
        "finally:\n",
        "    session.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Manually add single entries\n",
        "You can also insert data manually into the table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "manually_inserted_data = {\n",
        "    'id': 99999,\n",
        "    'center_lon': 12,\n",
        "    'center_lat': 52,\n",
        "    'rs': '99999',\n",
        "    'gen': 'Atlantis',\n",
        "    'wsk': '2021-01-20',\n",
        "    'ewz': 1234567,\n",
        "    'kfl': 0.0,\n",
        "    'hat_bez': True,\n",
        "    'geometry_wkt': 'POINT(12 52)'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    insert_statement = ExampleTable.insert().values([manually_inserted_data])\n",
        "    session.execute(insert_statement)\n",
        "    session.commit()\n",
        "    print('Insert successful!')\n",
        "except Exception as e:\n",
        "    session.rollback()\n",
        "    print('Insert incomplete!')\n",
        "finally:\n",
        "    session.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select from Table\n",
        "\n",
        "Now  we can query our table to see if the data arrived."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(session.query(ExampleTable).all())\n",
        "session.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Storing Query Result in DataFrame\n",
        "We can write the results of the query back into a DataFrame, where it's easier to handle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(session.query(ExampleTable).all())\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
